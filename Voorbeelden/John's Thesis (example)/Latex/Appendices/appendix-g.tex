\appendix 

\chapter{Appendix G}
\label{appendix:appSQL}
\section{Maximum F1 per corpus, language and algorithm}
\label{appSQLQueries}

Table \ref{tabMaxF1} contains the maximum values of F1 per language, corpus, and method, together with the hyperparameters that were used to obtain this value for F1. The optimal hyperparameters for evaluating iterations 1, 2, and 3 were done with this table.\\


\begin{table}[!ht]
	\centering
	\captionsetup{justification=centering}
    \begin{tabular}{l|l|l|l|l|l|l}
    \hline
        \textbf{Lang} & \textbf{Corpus} & \textbf{Method} & \textbf{NN} & \textbf{Hyperparameters} & \textbf{F1} & \textbf{\% incr.} \\ \hline
en & Wikisim & SBERT & plain & 70/30/30/12/20/200/0.1 & 0.96 & 120 \\ \hline
en & Wikisim & SBERT & stat & 80/50/10/12/50/10/0.01 & 0.66 & 82 \\ \hline
en & Wikisim & Sent2Vec & plain & 80/50/30/12/50/200/0.01 & 0.85 & 110 \\ \hline
en & Wikisim & Sent2Vec & stat & 80/40/10/12/100/10/0.001 & 0.66 & 85 \\ \hline
en & Wikisim & use & plain & 30/40/10/9/20/200/0.01 & 0.94 & 124 \\ \hline
en & Wikisim & use & stat & 80/30/10/12/50/10/0.001 & 0.66 & 87 \\ \hline
en & Wikisim & Word2Vec & plain & 80/20/20/12/100/200/0.01 & 0.84 & 111 \\ \hline
en & Wikisim & Word2Vec & stat & 80/30/10/12/100/10/0.001 & 0.66 & 88 \\ \hline
en & WiRe & SBERT & plain & 80/30/10/12/50/200/0.01 & 0.94 & 120 \\ \hline
en & WiRe & SBERT & stat & 80/50/10/12/100/10/0.001 & 0.68 & 87 \\ \hline
en & WiRe & Sent2Vec & plain & 30/30/30/12/50/200/0.01 & 0.81 & 110 \\ \hline
en & WiRe & Sent2Vec & stat & 80/50/10/12/100/10/0.001 & 0.68 & 93 \\ \hline
en & WiRe & use & plain & 80/50/20/12/100/200/0.01 & 0.88 & 116 \\ \hline
en & WiRe & use & stat & 80/50/10/12/100/10/0.01 & 0.68 & 90 \\ \hline
en & WiRe & Word2Vec & plain & 70/30/30/12/100/60/0.01 & 0.79 & 104 \\ \hline
en & WiRe & Word2Vec & stat & 80/50/10/9/100/10/0.001 & 0.68 & 90 \\ \hline
nl & Wikisim & SBERT & plain & 50/40/20/9/100/200/0.1 & 0.94 & 119 \\ \hline
nl & Wikisim & SBERT & stat & 80/50/10/12/100/10/0.001 & 0.66 & 84 \\ \hline
nl & Wikisim & Sent2Vec & plain & 50/20/30/12/20/200/0.01 & 0.93 & 128 \\ \hline
nl & Wikisim & Sent2Vec & stat & 80/40/10/9/100/10/0.001 & 0.66 & 91 \\ \hline
nl & Wikisim & use & plain & 30/30/20/12/50/200/0.1 & 0.94 & 114 \\ \hline
nl & Wikisim & use & stat & 80/40/10/12/50/10/0.001 & 0.66 & 80 \\ \hline
nl & Wikisim & Word2Vec & plain & 70/20/30/9/100/200/0.01 & 0.83 & 113 \\ \hline
nl & Wikisim & Word2Vec & stat & 80/40/10/12/20/100/0.1 & 0.66 & 90 \\ \hline
nl & WiRe & SBERT & plain & 80/50/30/12/20/200/0.1 & 0.88 & 112 \\ \hline
nl & WiRe & SBERT & stat & 80/50/10/9/100/10/0.001 & 0.68 & 86 \\ \hline
nl & WiRe & Sent2Vec & plain & 50/20/10/12/50/200/0.01 & 0.79 & 116 \\ \hline
nl & WiRe & Sent2Vec & stat & 80/50/10/9/100/10/0.01 & 0.68 & 100 \\ \hline
nl & WiRe & use & plain & 50/50/10/12/20/200/0.01 & 0.88 & 115 \\ \hline
nl & WiRe & use & stat & 80/50/10/9/100/10/0.001 & 0.68 & 89 \\ \hline
nl & WiRe & Word2Vec & plain & 30/50/30/12/50/200/0.01 & 0.74 & 105 \\ \hline
nl & WiRe & Word2Vec & stat & 80/50/10/12/20/10/0.1 & 0.68 & 97 \\ \hline
    \end{tabular}
    \caption{The column "Hyperparameters" contains the following values: Similarity/Maxdoc/Nearest Neighbors/Sections/Batch size/Epochs/Learning rate. Column "\% incr." contains the percentual increase in F1 compared to the baseline measurement.}
    \label{tabMaxF1}
\end{table}


\section{SQL queries}
This section contains the SQL queries that were used to obtain the results from the PostgreSQL database.\\

\begin{verbatim}
/* 
   Create a view that selects the most optimal results using 
   the embeddings by language, corpus and embedding method 
*/
create or replace view best_embeddings as
select *
from  embeddings e
where not exists (
    select *
    from   embeddings lg
    where  lg.Language = e.Language 
    and    lg.corpus  = e.corpus 
    and    lg.method = e.Method 
    and    lg.f1 > e.f1
 );



/* Query to select the values of using the embeddings on the document */
select language Lang,
       corpus Corpus,
       method Method,
       round(cast( f1 as numeric), 2) F1,
       round( cast( accuracy as numeric), 2) Accuracy
from best_embeddings
order by language, corpus, method
\end{verbatim}
\pagebreak
\begin{verbatim}

/* Query to select results for iterations, generates a LateX table body */
    with maxF1( language, method, nntype, f1)
    as (select language, method, nntype, max(f1)
        from "resultsK5"
        group by language, method, nntype
        order by 1, 2, 3)
    select  r.language || ' & ' || r.corpus || ' & ' || r.method || ' & ' ||
            r.similarity || '/' || r.maxdoc || '/' || r.nn || '/' || r.n ||  '/' || r.batchsize || '/' || r.epochs || '/' || r.learningrate
            || ' & ' ||  round( cast( r.f1 as numeric), 2)
            || ' \\ \hline'
    from maxF1 m inner join "resultsK5" r on(
        m.language = r.language
        and    m.nntype = r.nntype
        and    m.method = r.method
        and    m.f1     = r.f1
        and not exists(
            select *
            from "resultsK5" s
            where s.language = r.language
                and    s.nntype = r.nntype
                and    s.method = r.method
                and    s.f1     = r.f1
                and    s.index > r.index
        )
    )
        inner join best_embeddings e on (
            e.language = r.language
        and e.corpus = r.corpus
        and e.method = r.method)
    order by r.language, r.method, r.nntype, r.f1


/* Query to select the results, nntype and method can be different */
    select  r.language || ' & ' || r.corpus || ' & ' || r.method
            || ' & ' ||  round( cast( r.f1 as numeric), 2)
            || ' & ' ||  round( cast( r.accuracy as numeric), 2)
            || ' & ' ||  round( cast( e.f1 as numeric), 2)
            || ' & ' ||  round( cast( e.accuracy as numeric), 2)
            || ' \\ \hline'
    from "resultsK5" r inner join best_embeddings e
            on (r.language = e.language and r.corpus = e.corpus
                and r.method = e.method)
    where r.similarity = 30
    and   r.maxdoc = 40
    and   r.nn = 20
    and   r.n = 9
    and   r.batchsize = 50
    and   r.epochs = 100
    and   r.learningrate = 0.1
    and   r.nntype = 'plain'
    and   r.method in ('Sent2Vec', 'Word2Vec')
order by r.language, r.corpus, r.method


/* Select the average training F1 and accuracy compared to the base 
   The output is formatted as a Latex table */



SELECT
    r.language || ' & ' || r.corpus || ' & ' || r.method || ' & ' || r.nntype
            || ' & ' ||  round( cast( avg(r.f1) as numeric), 2)
            || ' & ' ||  round( cast( avg(r.accuracy) as numeric), 2)
            || ' & ' ||  round( cast( avg( e.f1) as numeric), 2)
            || ' & ' ||  round( cast( avg( e.accuracy) as numeric), 2)
            || ' & ' ||  CASE WHEN avg(r.f1) > avg(e.f1) THEN '+' ELSE '-' END

            || ' \\ \hline'

FROM "resultsTT" r INNER JOIN embeddings e ON (
            e.language = r.language
        AND r.method = e.method
        AND r.corpus = e.corpus
    )
WHERE r.f1 > 0.5
GROUP BY r.language, r.nntype, r.method, r.corpus






/* Fill the sizes of the document pairs per corpus and language */
insert into pairs( corpus, language, count) values( 'Wikisim', 'nl', 203);
insert into pairs( corpus, language, count) values( 'Wikisim', 'en', 256);
insert into pairs( corpus, language, count) values( 'WiRe', 'en', 426);
insert into pairs( corpus, language, count) values( 'WiRe', 'nl', 310);
insert into pairs( corpus, language, count) values( 'gwikimatch', 'nl', 13174);
insert into pairs( corpus, language, count) values( 'gwikimatch', 'nl', 2918);
\end{verbatim}



